{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik5rqleB5oR7"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXTDSVtu5oR-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBSsClBm5oR_"
      },
      "source": [
        "# Fixed RandomSeed & Setting Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5Z3e4Ac5oSA"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBMCd6Mi5oSA"
      },
      "outputs": [],
      "source": [
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFYlca7K5oSA"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D5HrjIR5oSA",
        "outputId": "74d23830-81eb-4eb7-b5ed-cb1542dafbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/LG_Aimers_해커톤_7기_Fiveguys/DATA/train/train.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byyRbTKo5oSB"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT6kACdQ5oSB"
      },
      "outputs": [],
      "source": [
        "class MultiOutputLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2, output_dim=7):\n",
        "        super(MultiOutputLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])  # (B, output_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeKKozSy5oSB"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka2iXiTO5oSC"
      },
      "outputs": [],
      "source": [
        "def train_lstm(train_df):\n",
        "    trained_models = {}\n",
        "\n",
        "    for store_menu, group in tqdm(train_df.groupby(['영업장명_메뉴명']), desc ='Training LSTM'):\n",
        "        store_train = group.sort_values('영업일자').copy()\n",
        "        if len(store_train) < LOOKBACK + PREDICT:\n",
        "            continue\n",
        "\n",
        "        features = ['매출수량']\n",
        "        scaler = MinMaxScaler()\n",
        "        store_train[features] = scaler.fit_transform(store_train[features])\n",
        "        train_vals = store_train[features].values  # shape: (N, 1)\n",
        "\n",
        "        # 시퀀스 구성\n",
        "        X_train, y_train = [], []\n",
        "        for i in range(len(train_vals) - LOOKBACK - PREDICT + 1):\n",
        "            X_train.append(train_vals[i:i+LOOKBACK])\n",
        "            y_train.append(train_vals[i+LOOKBACK:i+LOOKBACK+PREDICT, 0])\n",
        "\n",
        "        X_train = torch.tensor(X_train).float().to(DEVICE)\n",
        "        y_train = torch.tensor(y_train).float().to(DEVICE)\n",
        "\n",
        "        model = MultiOutputLSTM(input_dim=1, output_dim=PREDICT).to(DEVICE)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(EPOCHS):\n",
        "            idx = torch.randperm(len(X_train))\n",
        "            for i in range(0, len(X_train), BATCH_SIZE):\n",
        "                batch_idx = idx[i:i+BATCH_SIZE]\n",
        "                X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        trained_models[store_menu] = {\n",
        "            'model': model.eval(),\n",
        "            'scaler': scaler,\n",
        "            'last_sequence': train_vals[-LOOKBACK:]  # (28, 1)\n",
        "        }\n",
        "\n",
        "    return trained_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0evAd3n_5oSC",
        "outputId": "79bdb9aa-3e1d-44b5-dd16-78dc2dcab84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining LSTM:   0%|          | 0/193 [00:00<?, ?it/s]/tmp/ipython-input-2939504505.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  X_train = torch.tensor(X_train).float().to(DEVICE)\n",
            "Training LSTM: 100%|██████████| 193/193 [55:32<00:00, 17.27s/it]\n"
          ]
        }
      ],
      "source": [
        "# 학습\n",
        "trained_models = train_lstm(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5jMbzNW5oSC"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDmEVzqp5oSC"
      },
      "outputs": [],
      "source": [
        "def predict_lstm(test_df, trained_models, test_prefix: str):\n",
        "    results = []\n",
        "\n",
        "    for store_menu, store_test in test_df.groupby(['영업장명_메뉴명']):\n",
        "        key = store_menu\n",
        "        if key not in trained_models:\n",
        "            continue\n",
        "\n",
        "        model = trained_models[key]['model']\n",
        "        scaler = trained_models[key]['scaler']\n",
        "\n",
        "        store_test_sorted = store_test.sort_values('영업일자')\n",
        "        recent_vals = store_test_sorted['매출수량'].values[-LOOKBACK:]\n",
        "        if len(recent_vals) < LOOKBACK:\n",
        "            continue\n",
        "\n",
        "        # 정규화\n",
        "        recent_vals = scaler.transform(recent_vals.reshape(-1, 1))\n",
        "        x_input = torch.tensor([recent_vals]).float().to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(x_input).squeeze().cpu().numpy()\n",
        "\n",
        "        # 역변환\n",
        "        restored = []\n",
        "        for i in range(PREDICT):\n",
        "            dummy = np.zeros((1, 1))\n",
        "            dummy[0, 0] = pred_scaled[i]\n",
        "            restored_val = scaler.inverse_transform(dummy)[0, 0]\n",
        "            restored.append(max(restored_val, 0))\n",
        "\n",
        "        # 예측일자: TEST_00+1일 ~ TEST_00+7일\n",
        "        pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(PREDICT)]\n",
        "\n",
        "        for d, val in zip(pred_dates, restored):\n",
        "            results.append({\n",
        "                '영업일자': d,\n",
        "                '영업장명_메뉴명': store_menu,\n",
        "                '매출수량': val\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "5mu520gC5oSC",
        "outputId": "d8a8be8a-8dc5-40b6-c1dd-6f01b2031cd3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2400271947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mall_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mfull_pred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_keys_and_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ],
      "source": [
        "all_preds = []\n",
        "\n",
        "# 모든 test_*.csv 순회\n",
        "test_files = sorted(glob.glob('/content/drive/MyDrive/LG_Aimers_해커톤_7기_Fiveguys/DATA/test/TEST_*.csv'))\n",
        "\n",
        "for path in test_files:\n",
        "    test_df = pd.read_csv(path)\n",
        "\n",
        "    # 파일명에서 접두어 추출 (예: TEST_00)\n",
        "    filename = os.path.basename(path)\n",
        "    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n",
        "\n",
        "    pred_df = predict_lstm(test_df, trained_models, test_prefix)\n",
        "    all_preds.append(pred_df)\n",
        "\n",
        "full_pred_df = pd.concat(all_preds, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL_sfxLq5oSD"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CCHJDbp5oSD"
      },
      "outputs": [],
      "source": [
        "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
        "    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n",
        "    pred_dict = dict(zip(\n",
        "        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n",
        "        pred_df['매출수량']\n",
        "    ))\n",
        "\n",
        "    final_df = sample_submission.copy()\n",
        "\n",
        "    for row_idx in final_df.index:\n",
        "        date = final_df.loc[row_idx, '영업일자']\n",
        "        for col in final_df.columns[1:]:  # 메뉴명들\n",
        "            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DBbIMF55oSD"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('/content/drive/MyDrive/LG_Aimers_해커톤_7기_Fiveguys/DATA/sample_submission.csv')\n",
        "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
        "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "seohee",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}